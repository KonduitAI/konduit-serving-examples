{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ONNX Runtime for inference with Konduit Serving \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from urllib.request import urlretrieve \n",
    "dl_path = os.path.abspath(\"../data/facedetector/facedetector.onnx\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/master/models/onnx/version-RFB-320.onnx\"\n",
    "if not os.path.isfile(dl_path):\n",
    "    urlretrieve(DOWNLOAD_URL, filename=dl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import optimizer\n",
    "\n",
    "onnx_model = onnx.load(dl_path)\n",
    "passes = [\"extract_constant_to_initializer\", \"eliminate_unused_initializer\"]\n",
    "optimized_model = optimizer.optimize(onnx_model, passes)\n",
    "onnx.save(optimized_model, dl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = \"\"\"\n",
    "\n",
    "from PIL import Image \n",
    "import torchvision.transforms as transforms\n",
    "import onnxruntime\n",
    "import io \n",
    "import base64\n",
    "import os \n",
    "from utils import base64_to_ndarray\n",
    "dl_path = os.path.abspath(\"../data/facedetector/facedetector.onnx\")\n",
    "\n",
    "image = Image.fromarray(image.astype('uint8')[0], 'RGB')\n",
    "resize = transforms.Resize([240, 320])\n",
    "img_y = resize(image)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img_y)\n",
    "img_y.unsqueeze_(0)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "input_img = to_numpy(img_y)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(dl_path)\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y = ort_outs[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from konduit import PythonConfig, ServingConfig, InferenceConfiguration\n",
    "from konduit import PythonStep\n",
    "from konduit.server import Server\n",
    "from konduit.client import Client \n",
    "from konduit.utils import default_python_path\n",
    "\n",
    "import sys \n",
    "import numpy as np \n",
    "import time \n",
    "from PIL import Image \n",
    "\n",
    "work_dir = os.path.abspath('.')\n",
    "\n",
    "python_config = PythonConfig(\n",
    "    python_code=python_code,\n",
    "    python_inputs={\"image\": \"NDARRAY\"}, \n",
    "    python_outputs={\"img_out_y\": \"NDARRAY\"}, \n",
    "    python_path=default_python_path(work_dir)\n",
    ")\n",
    "\n",
    "onnx_step = PythonStep().step(python_config)\n",
    "\n",
    "port = np.random.randint(1000, 65535)\n",
    "\n",
    "server = Server(\n",
    "    steps=onnx_step, \n",
    "    serving_config=ServingConfig(http_port=port)\n",
    ")\n",
    "\n",
    "server.start()\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@type': 'InferenceConfiguration',\n",
       " 'pipelineSteps': [{'@type': 'PythonStep',\n",
       "   'inputSchemas': {'default': ['NDArray']},\n",
       "   'outputSchemas': {'default': ['NDArray']},\n",
       "   'inputNames': ['default'],\n",
       "   'outputNames': ['default'],\n",
       "   'inputColumnNames': {'default': ['image']},\n",
       "   'outputColumnNames': {'default': ['img_out_y']},\n",
       "   'pythonConfigs': {'default': {'@type': 'PythonConfig',\n",
       "     'pythonCode': '\\n\\nfrom PIL import Image \\nimport torchvision.transforms as transforms\\nimport onnxruntime\\nimport io \\nimport base64\\nimport os \\nfrom utils import base64_to_ndarray\\ndl_path = os.path.abspath(\"../data/facedetector/facedetector.onnx\")\\n\\nimage = Image.fromarray(image.astype(\\'uint8\\')[0], \\'RGB\\')\\nresize = transforms.Resize([240, 320])\\nimg_y = resize(image)\\nto_tensor = transforms.ToTensor()\\nimg_y = to_tensor(img_y)\\nimg_y.unsqueeze_(0)\\n\\ndef to_numpy(tensor):\\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\\n\\ninput_img = to_numpy(img_y)\\n\\nort_session = onnxruntime.InferenceSession(dl_path)\\nort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\\nort_outs = ort_session.run(None, ort_inputs)\\nimg_out_y = ort_outs[0]\\n',\n",
       "     'pythonInputs': {'image': 'NDARRAY'},\n",
       "     'pythonOutputs': {'img_out_y': 'NDARRAY'},\n",
       "     'pythonPath': 'C:\\\\Users\\\\Skymind AI Berhad\\\\Documents\\\\konduit-serving-examples\\\\python;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\python37.zip;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\DLLs;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch;;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\konduit-0.1.4-py3.7.egg;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\pyyaml-5.1.2-py3.7-win-amd64.egg;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\win32;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\win32\\\\lib;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\Pythonwin;C:\\\\Users\\\\Skymind AI Berhad\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\IPython\\\\extensions;C:\\\\Users\\\\Skymind AI Berhad\\\\.ipython;C:\\\\Users\\\\Skymind AI Berhad\\\\Documents\\\\konduit-serving-examples\\\\python'}}}],\n",
       " 'servingConfig': {'@type': 'ServingConfig',\n",
       "  'httpPort': 50979,\n",
       "  'inputDataType': 'NUMPY',\n",
       "  'outputDataType': 'NUMPY',\n",
       "  'logTimings': True}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.config.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.9309567  0.06904326]\n",
      "  [0.9341099  0.06589006]\n",
      "  [0.935605   0.06439508]\n",
      "  ...\n",
      "  [0.93740726 0.06259278]\n",
      "  [0.94315267 0.05684736]\n",
      "  [0.95290583 0.04709423]]]\n"
     ]
    }
   ],
   "source": [
    "client = Client(\n",
    "    input_type='NUMPY',\n",
    "    return_output_type='NUMPY',\n",
    "    endpoint_output_type=\"RAW\",\n",
    "    url='http://localhost:' + str(port)\n",
    ")\n",
    "\n",
    "im = Image.open(\"../data/facedetector/1.jpg\")\n",
    "im = np.array(im).astype(\"int\")\n",
    "\n",
    "a = client.predict(\n",
    "    {\"default\": im}\n",
    ")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
