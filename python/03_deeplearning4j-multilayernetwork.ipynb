{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve an image classification model built in Deeplearning4j with Konduit Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates a simple client-server interaction to perform inference on a Deeplearning4j image classification model using the Python SDK for Konduit Serving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konduit import ModelConfig, TensorDataTypesConfig, ModelConfigType, ModelPipelineStep, ParallelInferenceConfig, \\\n",
    "ServingConfig, InferenceConfiguration\n",
    "\n",
    "from konduit.server import Server\n",
    "from konduit.client import Client\n",
    "import numpy as np \n",
    "\n",
    "import time\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models in Deeplearning4j \n",
    "The following is a short Java program that loads a simple CNN model from Deeplearning4j's model zoo, initializes weights, then saves the model to a new file, \"SimpleCNN.zip\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```java\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.zoo.ZooModel;\n",
    "import org.deeplearning4j.zoo.model.SimpleCNN;\n",
    "\n",
    "import java.io.File;\n",
    "\n",
    "public class SaveSimpleCNN {\n",
    "    private static int nClasses = 5;\n",
    "    private static boolean saveUpdater = false;\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        ZooModel zooModel = SimpleCNN.builder()\n",
    "            .numClasses(nClasses)\n",
    "            .inputShape(new int[]{3, 224, 224})\n",
    "            .build();\n",
    "        MultiLayerConfiguration conf = ((SimpleCNN) zooModel).conf();\n",
    "        MultiLayerNetwork net = new MultiLayerNetwork(conf);\n",
    "        net.init();\n",
    "        System.out.println(net.summary());\n",
    "        File locationToSave = new File(\"SimpleCNN.zip\");\n",
    "        net.save(locationToSave, saveUpdater);\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "A reference Java project using Deeplearning4j 1.0.0-beta5 is provided in this repository with a Maven `pom.xml` dependencies file. If using the IntelliJ IDEA IDE, open the `java` folder as a Maven project and run the `main` function of the `SaveSimpleCNN` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the server \n",
    "\n",
    "### Configuring `ModelPipelineStep` \n",
    "\n",
    "Define the TensorFlow configuration as a `TensorFlowConfig` object. \n",
    "\n",
    "- `tensor_data_types_config`: The ModelConfig object requires a dictionary `input_data_types`. Its keys should represent column names, and the values should represent data types as strings, e.g. `\"INT32\"`. See [here](https://github.com/KonduitAI/konduit-serving/blob/master/konduit-serving-api/src/main/java/ai/konduit/serving/model/TensorDataType.java) for a list of supported data types. \n",
    "- `model_config_type`: This argument requires a `ModelConfigType` object. In the Java program above, we recognised that SimpleCNN is configured as a MultiLayerNetwork, in contrast with the ComputationGraph class, which is used for more complex networks. Specify `model_type` as `MULTI_LAYER_NETWORK`, and `model_loading_path` to point to the location of Deeplearning4j weights saved in the ZIP file format.\n",
    "\n",
    "\n",
    "For the `ModelPipelineStep` object, the  following parameters are specified: \n",
    "- `model_config`: pass the ModelConfig object here \n",
    "- `parallel_inference_config`: specify the number of workers to run in parallel. Here, we specify `workers = 1`.\n",
    "- `input_names`:  names for the input data  \n",
    "- `output_names`: names for the output data\n",
    "\n",
    "To find the names of input and output nodes in Deeplearning4j, \n",
    "\n",
    "- for `input_names`, print the first element of `net.getLayerNames()`.\n",
    "- for `output_names`, check the last layer when printing `net.summary()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_types = {\"image_array\": \"FLOAT\"}\n",
    "input_names = list(input_data_types.keys())\n",
    "output_names = [\"output\"]\n",
    "port = np.random.randint(1000, 65535)\n",
    "\n",
    "dl4j_config = ModelConfig(\n",
    "    tensor_data_types_config=TensorDataTypesConfig(\n",
    "        input_data_types=input_data_types\n",
    "    ), \n",
    "    model_config_type=ModelConfigType(\n",
    "        model_type=\"MULTI_LAYER_NETWORK\", \n",
    "        model_loading_path=os.path.abspath(\"../data/multilayernetwork/SimpleCNN.zip\")\n",
    "    )\n",
    ")\n",
    "\n",
    "dl4j_pipeline_step = ModelPipelineStep(\n",
    "    model_config=dl4j_config,\n",
    "    parallel_inference_config=ParallelInferenceConfig(workers=1),\n",
    "    input_names=input_names,\n",
    "    output_names=output_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the server\n",
    "\n",
    "Specify the following:\n",
    "- `http_port`: select a random port.\n",
    "- `input_data_type`, `output_data_type`: Specify input and output data types as strings. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "ℹ Accepted input and output data types are as follows: \n",
    "    <ul>\n",
    "        <li> Input: JSON, ARROW, IMAGE, ND4J (not yet implemented) and NUMPY. </li>\n",
    "        <li> Output: NUMPY, JSON, ND4J (not yet implemented) and ARROW.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "The `ServingConfig` has to be passed to `InferenceConfiguration` in addition to the pipeline steps as a Python list. In this case, there is a single pipeline step: `dl4j_pipeline_step`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_config = ServingConfig(\n",
    "    http_port=port,\n",
    "    input_data_type='NUMPY',\n",
    "    output_data_type='NUMPY'\n",
    ")\n",
    "\n",
    "server = Server(\n",
    "    config=InferenceConfiguration(\n",
    "        serving_config=serving_config,\n",
    "        pipeline_steps=[dl4j_pipeline_step]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can use the `as_dict()` method of the `config` attribute of `server` to view the overall configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@type': 'InferenceConfiguration',\n",
       " 'pipelineSteps': [{'@type': 'ModelPipelineStep',\n",
       "   'inputNames': ['image_array'],\n",
       "   'outputNames': ['output'],\n",
       "   'modelConfig': {'@type': 'ModelConfig',\n",
       "    'tensorDataTypesConfig': {'@type': 'TensorDataTypesConfig',\n",
       "     'inputDataTypes': {'image_array': 'FLOAT'}},\n",
       "    'modelConfigType': {'@type': 'ModelConfigType',\n",
       "     'modelType': 'MULTI_LAYER_NETWORK',\n",
       "     'modelLoadingPath': 'C:\\\\Users\\\\Skymind AI Berhad\\\\Documents\\\\konduit-serving-examples\\\\data\\\\multilayernetwork\\\\SimpleCNN.zip'}},\n",
       "   'parallelInferenceConfig': {'@type': 'ParallelInferenceConfig',\n",
       "    'workers': 1}}],\n",
       " 'servingConfig': {'@type': 'ServingConfig',\n",
       "  'httpPort': 53083,\n",
       "  'inputDataType': 'NUMPY',\n",
       "  'outputDataType': 'NUMPY'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.config.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the client \n",
    "\n",
    "To configure the client, create a Client object with the following arguments: \n",
    "- `input_names`: names of the input data\n",
    "- `output_names`: names of the output data\n",
    "- `input_type`: data type passed to the server for inference\n",
    "- `endpoint_output_type`: data type returned by the server endpoint \n",
    "- `return_output_type`: data type to be returned to the client. Note that this argument can be used to convert the output returned from the server to the client into a different format, e.g. NUMPY to JSON.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    ⚠ Future versions of the Python SDK may remove the <code>input_names</code> and <code>output_names</code> arguments in <code>Client()</code>, since these are already specified in <code>ModelPipelineStep()</code>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    input_type='NUMPY',\n",
    "    endpoint_output_type='NUMPY',\n",
    "    return_output_type=\"NUMPY\",\n",
    "    url='http://localhost:' + str(port)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a (3, 224, 224) array of random numbers between 0 and 255 as input to the model for prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before requesting for a prediction, we normalize the image to be between 0 and 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image = np.random.randint(255, size=(3, 224, 224)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote config.json to path C:\\Users\\Skymind AI Berhad\\Documents\\konduit-serving-examples\\python\\config.json\n",
      "Running with args\n",
      "java -cp konduit.jar ai.konduit.serving.configprovider.KonduitServingMain --configPath C:\\Users\\Skymind AI Berhad\\Documents\\konduit-serving-examples\\python\\config.json --verticleClassName ai.konduit.serving.verticles.inference.InferenceVerticle\n",
      "[[4.1586593e-02 3.2325742e-01 2.5140349e-02 3.9734459e-05 6.0997599e-01]]\n"
     ]
    }
   ],
   "source": [
    "server.start()\n",
    "time.sleep(30)\n",
    "\n",
    "prediction = client.predict({\"image_array\": rand_image})\n",
    "print(prediction)\n",
    "\n",
    "server.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
